# w2v 预训练模型说明

1. 生成w2v模型

```
python src\pretrain\w2v.py
```
这一步自己调整embed数值我这边测试的是128的
生成速度很快，另外注意的是保存文件的位置


2. 模型在src\pretrain\  model.py和lstm。py两个文件

model为transformer文件

3. 训练使用
```

python  "src/2.5 - pretrain.py"
```
注意调整参数，内存不够的吧dataloader的 num_work删掉

训练可以加载以前的模型，建议单步调试，单批次训练:
1、训练一次，调整学习率
2、新学习率训练，上一个结果对比，好的话继续调整，
3、结果没有提升，学习率变为5分之一或者10分之一，载入上一个模型进行第二epoch的训练
4、重复 2

即，人工调整每一次训练的学习率


FN = "1"  # 预训练模型 这里改成模型文件名字即可